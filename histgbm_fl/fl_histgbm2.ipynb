{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xichenshe/IAI/scikit-learn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/xichenshe/IAI/scikit-learn/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as time\n",
    "\n",
    "from sklearn._loss.loss import (\n",
    "    _LOSSES,\n",
    "    BaseLoss,\n",
    "    AbsoluteError,\n",
    "    HalfBinomialLoss,\n",
    "    HalfMultinomialLoss,\n",
    "    HalfPoissonLoss,\n",
    "    HalfSquaredError,\n",
    "    PinballLoss,\n",
    ")\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin, is_classifier\n",
    "from sklearn.utils import check_random_state, resample\n",
    "from sklearn.utils.validation import (\n",
    "    check_is_fitted,\n",
    "    check_consistent_length,\n",
    "    _check_sample_weight,\n",
    ")\n",
    "\n",
    "from sklearn.utils._openmp_helpers import _openmp_effective_n_threads\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.metrics import check_scoring\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble._hist_gradient_boosting._gradient_boosting import _update_raw_predictions\n",
    "from sklearn.ensemble._hist_gradient_boosting.common import Y_DTYPE, X_DTYPE, G_H_DTYPE\n",
    "\n",
    "from sklearn.ensemble._hist_gradient_boosting.binning import _BinMapper\n",
    "from sklearn.ensemble._hist_gradient_boosting.grower import TreeGrower\n",
    "\n",
    "from ddsketch import DDSketch\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble._hist_gradient_boosting.common import HISTOGRAM_DTYPE\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as time\n",
    "import numbers\n",
    "\n",
    "from sklearn.ensemble._hist_gradient_boosting.grower import TreeNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=5, n_informative=4, n_redundant=0, n_repeated=0, n_classes=2, random_state=23)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "\n",
    "X_train0 = X_train[:int(X_train.shape[0] / 2), :]\n",
    "X_train1 = X_train[int(X_train.shape[0] / 2):, :]\n",
    "y_train0 = y_train[:int(X_train.shape[0] / 2)]\n",
    "y_train1 = y_train[int(X_train.shape[0] / 2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define server and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_histograms(hist_lst):\n",
    "    hist_merge = np.zeros(shape=hist_lst[0].shape, dtype=HISTOGRAM_DTYPE)\n",
    "    for feature_idx in range(hist_merge.shape[0]):\n",
    "        for bin_idx in range(hist_merge.shape[1]):\n",
    "            for hist_ii in  hist_lst:\n",
    "                hist_merge[feature_idx, bin_idx][\"count\"] += hist_ii[feature_idx, bin_idx][\"count\"]\n",
    "                hist_merge[feature_idx, bin_idx][\"sum_gradients\"] += hist_ii[feature_idx, bin_idx][\"sum_gradients\"]\n",
    "                hist_merge[feature_idx, bin_idx][\"sum_hessians\"] += hist_ii[feature_idx, bin_idx][\"sum_hessians\"]\n",
    "\n",
    "    return hist_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistGbmServer:\n",
    "    def __init__(self, max_bins=255):\n",
    "        self.max_bins = max_bins\n",
    "        self.quantiles = np.linspace(0, 1, num=max_bins + 1)[1:-1]  # +1 for the bin for missing values\n",
    "\n",
    "    def aggregate_quantile_sketch(self, clients_skt_lst):\n",
    "        n_features = np.array([len(client) for client in clients_skt_lst])\n",
    "        assert np.all(n_features == n_features[0]), \"number of features differs across clients!\"\n",
    "\n",
    "        bin_thresh = []\n",
    "        for f_idx in range(n_features[0]):\n",
    "            skt_merge = clients_skt_lst[0][f_idx]\n",
    "            for ii in range(1, len(clients_skt_lst)):\n",
    "                skt_merge.merge(clients_skt_lst[ii][f_idx])\n",
    "            q_merge = [skt_merge.get_quantile_value(q) for q in self.quantiles]\n",
    "            bin_thresh.append(np.array(q_merge))\n",
    "        return bin_thresh\n",
    "\n",
    "    def aggregate_baseline_prediction(self, clients_baseline):\n",
    "        return np.average(\n",
    "            [x[0] for x in clients_baseline],\n",
    "            weights=[x[1] for x in clients_baseline]\n",
    "        )\n",
    "\n",
    "    def aggregate_root_attr(self, clients_root_attr):\n",
    "        return (\n",
    "            np.sum([x[0] for x in clients_root_attr], axis=0),\n",
    "            merge_histograms([x[1] for x in clients_root_attr])\n",
    "        )\n",
    "\n",
    "    def aggregate_next_node_attr(self, clients_next_node_attr):\n",
    "        left_n_sample = 0\n",
    "        right_n_sample = 0\n",
    "        left_histogram_lst = []\n",
    "        right_histogram_lst = []\n",
    "        for client in clients_next_node_attr:\n",
    "            left_n_sample += client[0][0]\n",
    "            right_n_sample += client[1][0]\n",
    "            left_histogram_lst.append(client[0][1])\n",
    "            right_histogram_lst.append(client[1][1])\n",
    "        return [int(left_n_sample), merge_histograms(left_histogram_lst)], [int(right_n_sample), merge_histograms(right_histogram_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistGbmClient:\n",
    "    def __init__(self, sketch_relative_accuracy, max_depth, random_state):\n",
    "        self.sketch_relative_accuracy = sketch_relative_accuracy\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "\n",
    "    # Return a list of sketches, one for each column\n",
    "    # NOTE: the columns should be in the same order across clients\n",
    "    def quantile_sketch(self, X):\n",
    "        skt_lst = []\n",
    "        for f_idx in range(X.shape[1]):\n",
    "            skt_ii = DDSketch(relative_accuracy=self.sketch_relative_accuracy)\n",
    "            for v in X[:, f_idx]:\n",
    "                skt_ii.add(v)\n",
    "            skt_lst.append(skt_ii)\n",
    "        return skt_lst\n",
    "\n",
    "    def set_bin_thresh(self, bin_thresh):\n",
    "        self.bin_thresh = bin_thresh\n",
    "\n",
    "    def init_learner(self, X, y, sample_weight=None):\n",
    "        # TODO: handle regression tasks\n",
    "        self.histgbm = HistGradientBoostingClassifier(\n",
    "            max_depth=self.max_depth,\n",
    "            early_stopping=False,\n",
    "            random_state=self.random_state,\n",
    "            # the # of bins = len(bin_thresh) + 2 which includes the bin for missing values, here the max_bins does not include it, thus only + 1\n",
    "            max_bins=len(self.bin_thresh[0]) + 1,\n",
    "        )\n",
    "        X, y = self.histgbm._validate_data(X, y, dtype=[X_DTYPE], force_all_finite=False)\n",
    "        y = self.histgbm._encode_y(y)\n",
    "        check_consistent_length(X, y)\n",
    "        \n",
    "        # Do not create unit sample weights by default to later skip some\n",
    "        # computation\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = _check_sample_weight(sample_weight, X, dtype=np.float64)\n",
    "            # TODO: remove when PDP supports sample weights\n",
    "            self.histgbm._fitted_with_sw = True\n",
    "\n",
    "        rng = check_random_state(self.histgbm.random_state)\n",
    "        self.histgbm._random_seed = rng.randint(np.iinfo(np.uint32).max, dtype=\"u8\")\n",
    "\n",
    "        self.histgbm._validate_parameters()\n",
    "\n",
    "        # used for validation in predict\n",
    "        n_samples, self.histgbm._n_features = X.shape\n",
    "\n",
    "        self.histgbm.is_categorical_, self.histgbm.known_categories = self.histgbm._check_categories(X)\n",
    "\n",
    "        if isinstance(self.histgbm.loss, str):\n",
    "            self.histgbm._loss = self.histgbm._get_loss(sample_weight=sample_weight)\n",
    "        elif isinstance(self.histgbm.loss, BaseLoss):\n",
    "            self.histgbm._loss = self.histgbm.loss\n",
    "        \n",
    "        return X, y, sample_weight\n",
    "\n",
    "    def get_local_unlinked_baseline(self, y, sample_weight=None):\n",
    "        return np.average(y, weights=sample_weight, axis=0), y.shape[0]\n",
    "\n",
    "    def set_baseline(self, baseline_prediction):\n",
    "        self.histgbm._baseline_prediction = self.histgbm._loss.link.link(baseline_prediction).reshape((1, -1))\n",
    "\n",
    "    def bin_data(self, X, y, sample_weight=None):\n",
    "        # y needs to be encoded, i.e., the output from init_learner\n",
    "        X_train, y_train, sample_weight_train = X, y, sample_weight\n",
    "        X_val = y_val = sample_weight_val = None\n",
    "\n",
    "        # `_openmp_effective_n_threads` is used to take cgroups CPU quotes\n",
    "        # into account when determine the maximum number of threads to use.\n",
    "        n_threads = _openmp_effective_n_threads()\n",
    "        n_bins = self.histgbm.max_bins + 1  # +1 for missing values\n",
    "        self.histgbm._bin_mapper = _BinMapper(\n",
    "            n_bins=n_bins,\n",
    "            is_categorical=self.histgbm.is_categorical_,\n",
    "            known_categories=self.histgbm.known_categories,\n",
    "            random_state=self.histgbm._random_seed,\n",
    "            n_threads=n_threads,\n",
    "        )\n",
    "\n",
    "        X_binned_train = self.histgbm._bin_data(X_train, is_training_data=True, bin_thresholds=self.bin_thresh)\n",
    "        if X_val is not None:\n",
    "            X_binned_val = self.histgbm._bin_data(X_val, is_training_data=False)\n",
    "        else:\n",
    "            X_binned_val = None\n",
    "\n",
    "        # Uses binned data to check for missing values\n",
    "        self.histgbm.has_missing_values = (\n",
    "            (X_binned_train == self.histgbm._bin_mapper.missing_values_bin_idx_)\n",
    "            .any(axis=0)\n",
    "            .astype(np.uint8)\n",
    "        )\n",
    "        return X_binned_train, y_train, X_binned_val, y_val\n",
    "\n",
    "    def get_gradient_hession(self, X_binned, y):\n",
    "        y = self.histgbm._encode_y(y)\n",
    "        \n",
    "        # initialize gradients and hessians (empty arrays).\n",
    "        # shape = (n_samples, n_trees_per_iteration).\n",
    "        n_samples = X_binned.shape[0]\n",
    "        gradient, hessian = self.histgbm._loss.init_gradient_and_hessian(\n",
    "            n_samples=n_samples, dtype=G_H_DTYPE, order=\"F\"\n",
    "        )\n",
    "\n",
    "        # `_openmp_effective_n_threads` is used to take cgroups CPU quotes\n",
    "        # into account when determine the maximum number of threads to use.\n",
    "        n_threads = _openmp_effective_n_threads()\n",
    "\n",
    "        raw_predictions = np.zeros(\n",
    "            shape=(n_samples, self.histgbm.n_trees_per_iteration_),\n",
    "            dtype=self.histgbm._baseline_prediction.dtype,\n",
    "            order=\"F\",\n",
    "        )\n",
    "        raw_predictions += self.histgbm._baseline_prediction\n",
    "        # Update gradients and hessians, inplace\n",
    "        # Note that self.histgbm._loss expects shape (n_samples,) for\n",
    "        # n_trees_per_iteration = 1 else shape (n_samples, n_trees_per_iteration).\n",
    "        if self.histgbm._loss.constant_hessian:\n",
    "            self.histgbm._loss.gradient(\n",
    "                y_true=y,\n",
    "                raw_prediction=raw_predictions,\n",
    "                sample_weight=None,\n",
    "                gradient_out=gradient,\n",
    "                n_threads=n_threads,\n",
    "            )\n",
    "        else:\n",
    "            self.histgbm._loss.gradient_hessian(\n",
    "                y_true=y,\n",
    "                raw_prediction=raw_predictions,\n",
    "                sample_weight=None,\n",
    "                gradient_out=gradient,\n",
    "                hessian_out=hessian,\n",
    "                n_threads=n_threads,\n",
    "            )\n",
    "\n",
    "        # 2-d views of shape (n_samples, n_trees_per_iteration_) or (n_samples, 1)\n",
    "        # on gradient and hessian to simplify the loop over n_trees_per_iteration_.\n",
    "        if gradient.ndim == 1:\n",
    "            g_view = gradient.reshape((-1, 1))\n",
    "            h_view = hessian.reshape((-1, 1))\n",
    "        else:\n",
    "            g_view = gradient\n",
    "            h_view = hessian\n",
    "\n",
    "        return g_view, h_view\n",
    "\n",
    "    def init_grower(self, X, y, sample_weight=None):\n",
    "\n",
    "        X_binned_train, y_train, X_binned_val, y_val = self.bin_data(X, y, sample_weight=None)\n",
    "        g_view, h_view = self.get_gradient_hession(X_binned_train, y_train)\n",
    "        n_threads = _openmp_effective_n_threads()\n",
    "\n",
    "        # Build `n_trees_per_iteration` trees.\n",
    "        for k in range(self.histgbm.n_trees_per_iteration_):\n",
    "            self.grower = TreeGrower(\n",
    "                X_binned=X_binned_train,\n",
    "                gradients=g_view[:, k],\n",
    "                hessians=h_view[:, k],\n",
    "                n_bins=self.histgbm.max_bins + 1,\n",
    "                n_bins_non_missing=self.histgbm._bin_mapper.n_bins_non_missing_,\n",
    "                has_missing_values=self.histgbm.has_missing_values,\n",
    "                is_categorical=self.histgbm.is_categorical_,\n",
    "                monotonic_cst=self.histgbm.monotonic_cst,\n",
    "                max_leaf_nodes=self.histgbm.max_leaf_nodes,\n",
    "                max_depth=self.histgbm.max_depth,\n",
    "                min_samples_leaf=self.histgbm.min_samples_leaf,\n",
    "                l2_regularization=self.histgbm.l2_regularization,\n",
    "                shrinkage=self.histgbm.learning_rate,\n",
    "                n_threads=n_threads,\n",
    "            )\n",
    "\n",
    "    def get_root_attr(self):\n",
    "        return [self.grower.root.n_samples, self.grower.root.sum_gradients, self.grower.root.sum_hessians], self.grower.root.histograms\n",
    "\n",
    "    def split_root(self, root_attr):\n",
    "        self.grower.root.split_info = self.grower.splitter.find_node_split(\n",
    "            root_attr[0][0],\n",
    "            root_attr[1],\n",
    "            root_attr[0][1],\n",
    "            root_attr[0][2],\n",
    "            self.grower.root.value,\n",
    "            self.grower.root.children_lower_bound,\n",
    "            self.grower.root.children_upper_bound,\n",
    "        )\n",
    "\n",
    "    def prepare_next_node(self):\n",
    "        node = heappop(self.grower.splittable_nodes)\n",
    "        (\n",
    "            sample_indices_left,\n",
    "            sample_indices_right,\n",
    "            right_child_pos,\n",
    "        ) = self.grower.splitter.split_indices(node.split_info, node.sample_indices)\n",
    "\n",
    "        depth = node.depth + 1\n",
    "        n_leaf_nodes = len(self.grower.finalized_leaves) + len(self.grower.splittable_nodes)\n",
    "        n_leaf_nodes += 2\n",
    "\n",
    "        left_child_node = TreeNode(\n",
    "            depth,\n",
    "            sample_indices_left,\n",
    "            # NOTE: the sum gradient and hession are already the aggregated versions\n",
    "            node.split_info.sum_gradient_left,\n",
    "            node.split_info.sum_hessian_left,\n",
    "            value=node.split_info.value_left,\n",
    "        )\n",
    "        right_child_node = TreeNode(\n",
    "            depth,\n",
    "            sample_indices_right,\n",
    "            node.split_info.sum_gradient_right,\n",
    "            node.split_info.sum_hessian_right,\n",
    "            value=node.split_info.value_right,\n",
    "        )\n",
    "\n",
    "        node.right_child = right_child_node\n",
    "        node.left_child = left_child_node\n",
    "\n",
    "        # set start and stop indices\n",
    "        left_child_node.partition_start = node.partition_start\n",
    "        left_child_node.partition_stop = node.partition_start + right_child_pos\n",
    "        right_child_node.partition_start = left_child_node.partition_stop\n",
    "        right_child_node.partition_stop = node.partition_stop\n",
    "\n",
    "        if not self.grower.has_missing_values[node.split_info.feature_idx]:\n",
    "            # If no missing values are encountered at fit time, then samples\n",
    "            # with missing values during predict() will go to whichever child\n",
    "            # has the most samples.\n",
    "            node.split_info.missing_go_to_left = (\n",
    "                left_child_node.n_samples > right_child_node.n_samples\n",
    "            )\n",
    "\n",
    "        self.grower.n_nodes += 2\n",
    "        self.grower.n_categorical_splits += node.split_info.is_categorical\n",
    "\n",
    "        # if grower.max_leaf_nodes is not None and n_leaf_nodes == grower.max_leaf_nodes:\n",
    "        #     grower._finalize_leaf(left_child_node)\n",
    "        #     grower._finalize_leaf(right_child_node)\n",
    "        #     grower._finalize_splittable_nodes()\n",
    "        #     # return left_child_node, right_child_node\n",
    "\n",
    "        if self.grower.max_depth is not None and depth == self.grower.max_depth:\n",
    "            self.grower._finalize_leaf(left_child_node)\n",
    "            self.grower._finalize_leaf(right_child_node)\n",
    "            # return left_child_node, right_child_node\n",
    "        else:\n",
    "            # We will compute the histograms of both nodes even if one of them\n",
    "            # is a leaf, since computing the second histogram is very cheap\n",
    "            # (using histogram subtraction).\n",
    "            n_samples_left = left_child_node.sample_indices.shape[0]\n",
    "            n_samples_right = right_child_node.sample_indices.shape[0]\n",
    "            if n_samples_left < n_samples_right:\n",
    "                smallest_child = left_child_node\n",
    "                largest_child = right_child_node\n",
    "            else:\n",
    "                smallest_child = right_child_node\n",
    "                largest_child = left_child_node\n",
    "\n",
    "            smallest_child.histograms = self.grower.histogram_builder.compute_histograms_brute(\n",
    "                smallest_child.sample_indices\n",
    "            )\n",
    "            largest_child.histograms = (\n",
    "                self.grower.histogram_builder.compute_histograms_subtraction(\n",
    "                    node.histograms, smallest_child.histograms\n",
    "                )\n",
    "            )\n",
    "        self.left_child_node = left_child_node\n",
    "        self.right_child_node = right_child_node\n",
    "\n",
    "    def get_next_node_attr(self):\n",
    "        return [self.left_child_node.n_samples, self.left_child_node.histograms], [self.right_child_node.n_samples, self.right_child_node.histograms]\n",
    "\n",
    "    def split_next_node(self, next_node_attr):\n",
    "        self.grower._compute_best_split_and_push(self.left_child_node, next_node_attr[0][0], next_node_attr[0][1])\n",
    "        self.grower._compute_best_split_and_push(self.right_child_node, next_node_attr[1][0], next_node_attr[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = HistGbmServer(max_bins=255)\n",
    "client_0 = HistGbmClient(sketch_relative_accuracy=0.001, max_depth=2, random_state=23)\n",
    "client_1 = HistGbmClient(sketch_relative_accuracy=0.001, max_depth=2, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_skt_lst = [\n",
    "    client_0.quantile_sketch(X=X_train0),\n",
    "    client_1.quantile_sketch(X=X_train1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_thresh = server.aggregate_quantile_sketch(clients_skt_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5523125 , -2.37026032, -2.23669598, -2.13187048, -2.05648814,\n",
       "       -1.97585206, -1.90217832, -1.84965605, -1.79858401, -1.7454278 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_thresh[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.07552661, -3.74716645, -3.56441492, -3.43837822, -3.31017116,\n",
       "       -3.23167278, -3.14873216, -3.07406219, -3.00116296, -2.92999249])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_thresh[3][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_0.set_bin_thresh(bin_thresh)\n",
    "client_1.set_bin_thresh(bin_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated training\n",
    "\n",
    "### 1. set the global baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, y_train0, _ = client_0.init_learner(X_train0, y_train0)\n",
    "X_train1, y_train1, _ = client_1.init_learner(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_baseline = [\n",
    "    client_0.get_local_unlinked_baseline(y_train0),\n",
    "    client_1.get_local_unlinked_baseline(y_train1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_baseline = server.aggregate_baseline_prediction(clients_baseline)\n",
    "client_0.set_baseline(agg_baseline)\n",
    "client_1.set_baseline(agg_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. initialize root node and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_0.init_grower(X_train0, y_train0)\n",
    "client_1.init_grower(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_root_attr = [\n",
    "    client_0.get_root_attr(),\n",
    "    client_1.get_root_attr(),\n",
    "]\n",
    "agg_root_attr = server.aggregate_root_attr(clients_root_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_0.split_root(agg_root_attr)\n",
    "client_1.split_root(agg_root_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gain': 765.9620907859037,\n",
       " 'feature_idx': 4,\n",
       " 'bin_idx': 195,\n",
       " 'missing_go_to_left': 0,\n",
       " 'sum_gradient_left': 369.28099259734154,\n",
       " 'sum_hessian_left': 768.2223420739174,\n",
       " 'sum_gradient_right': -369.28101655840874,\n",
       " 'sum_hessian_right': 231.74165672063828,\n",
       " 'n_samples_left': 3073,\n",
       " 'n_samples_right': 927,\n",
       " 'value_left': -0.4806954606402345,\n",
       " 'value_right': 1.5935029626700756,\n",
       " 'is_categorical': 0,\n",
       " 'left_cat_bitset': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_0.grower.root.split_info.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. split next nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(client_0.grower.splittable_nodes) == len(client_1.grower.splittable_nodes), \"model out of sync across clients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(client_0.grower.splittable_nodes) > 0:\n",
    "    client_0.prepare_next_node()\n",
    "    client_1.prepare_next_node()\n",
    "    if client_0.left_child_node.histograms is not None:\n",
    "        clients_next_node_attr = [\n",
    "            client_0.get_next_node_attr(),\n",
    "            client_1.get_next_node_attr(),\n",
    "        ]\n",
    "        agg_next_node_attr = server.aggregate_next_node_attr(clients_next_node_attr)\n",
    "        client_0.split_next_node(agg_next_node_attr)\n",
    "        client_1.split_next_node(agg_next_node_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>num_threshold</th>\n",
       "      <th>missing_go_to_left</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>gain</th>\n",
       "      <th>depth</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>bin_threshold</th>\n",
       "      <th>is_categorical</th>\n",
       "      <th>bitset_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>765.962091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480695</td>\n",
       "      <td>1519</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026596</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>775.590298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.278917</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.784106</td>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.593503</td>\n",
       "      <td>481</td>\n",
       "      <td>3</td>\n",
       "      <td>1.029424</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>43.643797</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.721323</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.120112</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value  count  feature_idx  num_threshold  missing_go_to_left  left  \\\n",
       "0  0.000000   2000            4       0.394159                   1     1   \n",
       "1 -0.480695   1519            1      -0.026596                   1     2   \n",
       "2 -1.278917    938            0       0.000000                   0     0   \n",
       "3  0.784106    581            0       0.000000                   0     0   \n",
       "4  1.593503    481            3       1.029424                   1     5   \n",
       "5  1.721323    443            0       0.000000                   0     0   \n",
       "6  0.120112     38            0       0.000000                   0     0   \n",
       "\n",
       "   right        gain  depth  is_leaf  bin_threshold  is_categorical  \\\n",
       "0      4  765.962091      0        0            195               0   \n",
       "1      3  775.590298      1        0            155               0   \n",
       "2      0   -1.000000      2        1              0               0   \n",
       "3      0   -1.000000      2        1              0               0   \n",
       "4      6   43.643797      1        0            216               0   \n",
       "5      0   -1.000000      2        1              0               0   \n",
       "6      0   -1.000000      2        1              0               0   \n",
       "\n",
       "   bitset_idx  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(client_0.grower.make_predictor(bin_thresh).nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>num_threshold</th>\n",
       "      <th>missing_go_to_left</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>gain</th>\n",
       "      <th>depth</th>\n",
       "      <th>is_leaf</th>\n",
       "      <th>bin_threshold</th>\n",
       "      <th>is_categorical</th>\n",
       "      <th>bitset_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>765.962091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480695</td>\n",
       "      <td>1554</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026596</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>775.590298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.278917</td>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.784106</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.593503</td>\n",
       "      <td>446</td>\n",
       "      <td>3</td>\n",
       "      <td>1.029424</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>43.643797</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.721323</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.120112</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value  count  feature_idx  num_threshold  missing_go_to_left  left  \\\n",
       "0  0.000000   2000            4       0.394159                   1     1   \n",
       "1 -0.480695   1554            1      -0.026596                   1     2   \n",
       "2 -1.278917    946            0       0.000000                   0     0   \n",
       "3  0.784106    608            0       0.000000                   0     0   \n",
       "4  1.593503    446            3       1.029424                   1     5   \n",
       "5  1.721323    410            0       0.000000                   0     0   \n",
       "6  0.120112     36            0       0.000000                   0     0   \n",
       "\n",
       "   right        gain  depth  is_leaf  bin_threshold  is_categorical  \\\n",
       "0      4  765.962091      0        0            195               0   \n",
       "1      3  775.590298      1        0            155               0   \n",
       "2      0   -1.000000      2        1              0               0   \n",
       "3      0   -1.000000      2        1              0               0   \n",
       "4      6   43.643797      1        0            216               0   \n",
       "5      0   -1.000000      2        1              0               0   \n",
       "6      0   -1.000000      2        1              0               0   \n",
       "\n",
       "   bitset_idx  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(client_1.grower.make_predictor(bin_thresh).nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- grow multiple trees for multi-class targets\n",
    "- accumulate predictions then grow a sequence of trees for boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
